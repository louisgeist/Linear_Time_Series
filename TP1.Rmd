---
title: "R Notebook - Linear Time Series TP1"
output: html_notebook
---


# TP1 de séries temporelles linéaires

```{r}
rm(list = ls())
require(zoo) #format de serie temporelle pratique et facile d'utilisation (mais plus volumineux)
library("ggplot2")
library("tseries") # contient plus d e
```

### Question 1 - importatation des données
```{r}
donnees1 = read.csv(file="./Donnees/Donnees1.csv")

xm.source = zoo(donnees1)
n = length(donnees1$XM) - 4
xm = zoo(donnees1$XM[1:n])
```


### Question 2 - désaisonnalisation
```{r}
index = 1:n
data_display = as.data.frame(cbind(index,xm))
p1 = ggplot(data = data_display) + geom_line(aes(x=index,y=xm))
p1
```
On observe une saisonnalité de 12 mois.
Pour résoudre le problème de saisonnalité, on peut différencier la série avec un pas temporel de 12 mois.

```{r}
desaison = xm - lag(xm,-12)
plot(desaison)
```

L'exercice suppose que desaison suit un ARIMA(p,d,q).

### Question 3

```{r}
acf(desaison)
```
```{r}
pacf(desaison)
```
L'autocorrélogramme décroît à une vitesse exponentielle, donc la série semble maintenant bien stationnaire.

### Question 4 - test de racine unitaire
```{r}
plot(desaison)
pp.test(desaison)
```
*Test de Unit Root de Philips-Perront.*

On rejette de l'hypothèse nulle à 1%, qui était l'hypothèse de non-stationnarité.

Le test confirme donc bien les conclusions précédentes, la série est stationnaire.

### Question 5

En vertu du ACF, je prendrais $q=2$.
Le PACF semble indiquer $p=3$.

Ainsi, on veut tester si la série suit bien un $ARIMA(3,0,2)$.


```{r}
arima302 = arima(desaison - mean(desaison), c(3,0,2))

stats::Box.test(arima302$residuals,lag = 6, type="Ljung-Box",fitdf = 5)

```

"Box.test" : permet d'utiliser les tests de Box-Pierce ou Ljung-Box, c'est-à-dire tester s'il y a encore de la dynamique dans les résidus.
- fitdf : number of degrees of freedom to be substracted if $x$ is a series of residuals
  - donc ici fitdf = p+q = 5
  - lag : the statistic will be based on $lag$ autoorrelation coefficients
    - $lag=k$ dans mes notes Obsidian sur ces tests
  


```{r}
Qtests <- function(series, k, fitdf = 0){
  my_func<- function(l){
    pval = if(l<=fitdf) NA else Box.test(series,lag = l, type ="Ljung-Box",fitdf=fitdf)$p.value
    return(c("lag"=l,"pval"=pval))
  }

  pvals <- apply(matrix(1:k), 1, FUN = my_func)
  return(t(pvals))
}

Qtests(arima302$residuals, 25, 5) # test de Ljung-Box pour les ordres de 1 à 24
round(Qtests(arima302$residuals,24,fitdf=5),3)
```

On fait plein de fois le test de Ljung-Box (pour tous les ordres).

On ne rejette à aucun niveau usuel l'indépendance des résidus, pour n'importe quel lag entre 5 et 24 !

Ainsi, le modèle semble assez riche ("valide" selon la correction) pour cette série temporelle.

### Question 6
Les sous-modèles possibles sont les suivants :
- ARIMA(2,0,2)
- ARIMA(1,0,2)
- MA(0,2)

- ARIMA(3,0,1)
- ARIMA(2,0,1)
- ARIMA(1,0,1)
- MA(1)

- AR(3)
- AR(2)
- AR(1)

- ARIMA(0,0,0)

Pour choisir parmi ces modèles, il suffit de tester la nullité du coefficient p ou q du modèle actuellement considéré.

```{r}
signif <- function(estim){
  coef <- estim$coef
  se = sqrt(diag(estim$var.coef))
  t <- coef/se
  
  pval <- (1-pnorm(abs(t)))*2 # formule de la pvaleur pour un test de Student : on le retrouve facilement par le calcul
  return(rbind(coef,se,pval))
}

signif(arima302)
```

On ne rejette pas que coefficient $\phi_p$ et $\psi_q$ sont non nuls.

*Correction* : Aucun coefficient n'est statistiquement significatif. Notre ARIMA(3,0,2) ne semble donc pas bien ajusté.

```{r}
y = desaison - mean(desaison)

arimafit <- function(estim){
  adjust <- round(signif(estim),3)
  pvals <- Qtests(estim$residuals,24,length(estim$coef)-1)
  pvals <- matrix(apply(matrix(1:24,nrow=6),2,function(c) round(pvals[c,],3)),nrow=6)
  colnames(pvals) <- rep(c("lag", "pval"),4)
  cat("tests de nullite des coefficients :\n")
  print(adjust)
  cat("\n tests d'absence d'autocorrelation des residus : \n")
  print(pvals)
}

estim <- arima(y,c(1,0,0)); arimafit(estim)
# 

estim <- arima(y,c(2,0,0)); arimafit(estim)
# 

estim <- arima(y,c(3,0,0)); arimafit(estim)
# 
ar3 <- estim

estim <- arima(y,c(0,0,1)); arimafit(estim)
# 

estim <- arima(y,c(0,0,2)); arimafit(estim)
# 
ma2 <- estim

estim <- arima(y,c(1,0,1)); arimafit(estim)
# 

estim <- arima(y,c(1,0,2)); arimafit(estim)
# 

estim <- arima(y,c(2,0,1)); arimafit(estim)
# 
ar2ma1 <- estim

estim <- arima(y,c(2,0,2)); arimafit(estim)
# 


# 
models <- c("ar3","ma2","ar2ma1"); names(models) <- models
apply(as.matrix(models),1, function(m) c("AIC"=AIC(get(m)), "BIC"=BIC(get(m))))

```
Modèle AR(1) : bien ajusté mais pas valide, car autocorrélation des résidus
Modèle AR(2) : même pas bien ajusté

Le modèle AR(3) est le premier modèle où les coefficients sont tous significatifs et dont les résidus ne semblent pas avoir d'autocorrélation.
-> Modèle candidat A

MA(2) :  les deux coefficients sont significatifs et pas d'autocorrélation des résidus.
-> Modèle candidat B

Modèle sans autocorrrélation des résidus et avec des coefficients pas tous significatifs -> rejet du modèle, on ne le garde pas.

ARIMA(2,0,1) : on le garde pcq 2 coefs sur 3 significatifs et pas d'autocorrélation des résiduds

**Moi** : à mon avis, on garde un modèle qui a des coefficients non significiatifs, si le dernier coefficient de chaque ordre est bien significatif


### Question 7 - prévision avec les modèles
```{r}
##
models <-  c("ar3","ma2","ar2ma1")
preds <- zoo(matrix(NA,ncol=3,nrow=4),order.by=tail(index(xm.source),4))
colnames(preds) <- models
desaisonp <- preds #
xmp <- preds #

##
for (m in models){
  pred1 <- mean(desaison) + zoo(predict(get(m),4)$pred, order.by=tail(index(xm.source),4))
  pred2 <- as.numeric(tail(xm,12))[1:4] + pred1 # parce qu'on avait différencier de 12 en 12
  desaisonp[,m] <- pred1
  xmp[,m] <- pred2
}

obs <- tail(xm.source,4) #on stocke les valeurs observées
cbind(obs,xmp) #on les ajoute dans xmp
apply(xmp,2, function(x) sqrt(sum((x-obs)^2)/4)/sd(xm.source)) #calcul des RMSE

```

On calcule le RMSE pour déterminer lequel des 3 modèles fait la prévision de meilleure qualité


### Question 8 - refaire tout pour autres données
à faire pour semaine pro